{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian learning allows us to incorporate prior knowledge, and Empirical Data. \n",
    "\n",
    "**Source of Prior Knowledge**\n",
    "The notion that prior knowledge must be received from a divine or transcendent source, such as God, touches on epistemological and metaphysical questions:\n",
    "\n",
    "![Kaabe](../AI_Images/kaaba_TranscendentSourse.jpg)\n",
    "\n",
    "\n",
    "## Epistemological Perspective:\n",
    "From an epistemological standpoint, prior knowledge can be seen as originating from various sources, including \n",
    "- intuition\n",
    "- previous experience\n",
    "- expert opinion\n",
    "- theoretical considerations\n",
    "\n",
    "![Epitemological_Mohammad](../AI_Images/Nabi_Epistomological.jpg)\n",
    "\n",
    "### God\n",
    "The idea of this knowledge being divinely inspired or received from a higher power adds a layer of metaphysical depth. \n",
    "\n",
    "![Metaphisic](../AI_Images/metaphysical.jpg)\n",
    "\n",
    "It suggests that some forms of knowledge are beyond empirical verification and are grounded in a belief in a higher, possibly omniscient, source.\n",
    "\n",
    "### Metaphysical Perspective:\n",
    "Metaphysically, considering prior knowledge as divinely inspired of God. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk minimization in the Bayesian perspective\n",
    "\n",
    "### Steps for Bayesian Risk Minimization\n",
    "\n",
    "1. **Determine the Posterior Distribution**: Compute the posterior distribution $p(\\theta | X)$ using Bayes' theorem.\n",
    "\n",
    "$$\n",
    "p(\\theta | X) = \\frac{p(X | \\theta) p(\\theta)}{p(X)}\n",
    "$$\n",
    "\n",
    "2. **Define the Loss Function**: Choose an appropriate loss function $L(\\theta, \\theta^{*})$ based on the problem context.\n",
    "\n",
    "3. **Compute the Expected Posterior Loss**: Integrate the loss function over the posterior distribution to get the expected loss for each possible action.\n",
    "\n",
    "$$\n",
    "R(\\theta^{*} | X) = \\int L(\\theta, \\theta^{*}) p(\\theta | X) \\, d\\theta\n",
    "$$\n",
    "\n",
    "4. **Minimize the Expected Loss**: Select the action $a^*$ that minimizes the expected posterior loss.\n",
    "\n",
    "$$\n",
    "\\theta^{optimal} = \\arg\\min_\\theta R(\\theta | X)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
